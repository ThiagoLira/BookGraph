{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get books from goodreads metadata\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "metadata_goodreads = pickle.load(open( \"pickled_metadata/metadata_goodreads.p\", \"rb\" ))\n",
    "books = list(set(metadata_goodreads['clean_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [b for b in books if len(b.split())<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "books;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_jsonl_dataset(ds,augument_chance=0,book_list_to_pick=None,remove_negatives=True):\n",
    "    new_ds = []\n",
    "    \n",
    "    for d in ds:\n",
    "\n",
    "        if d['entities']:\n",
    "\n",
    "            if(np.random.rand()>1-augument_chance):\n",
    "\n",
    "                d_ = d.copy()\n",
    "                book = d_['entities'][0]['text']\n",
    "                book_to_change = np.random.choice(book_list_to_pick,1)[0]\n",
    "                temp = d_['text'].replace(book,book_to_change)\n",
    "                d_['text'] = temp\n",
    "\n",
    "\n",
    "                b = temp.find(book_to_change)\n",
    "                e = b + len(book_to_change)\n",
    "\n",
    "                #dict(start=5,end=14,text=\"Tal Perry\",label=\"Person\")\n",
    "                entities = {\n",
    "                    'start' : b,\n",
    "                    'end' : e,\n",
    "                    'text' : book_to_change,\n",
    "                    'label' : \"OBRA\",\n",
    "                    'tag' : \"OBRA\"\n",
    "                }\n",
    "\n",
    "                d_['meta']['book'] = book_to_change\n",
    "\n",
    "                d_['entities'] = [entities]\n",
    "                \n",
    "                # add original and augumented\n",
    "                new_ds.append(d_)\n",
    "            new_ds.append(d)   \n",
    "\n",
    "        else:\n",
    "            if(not remove_negatives):\n",
    "                print('opa')\n",
    "                new_ds.append(d) \n",
    "        \n",
    "\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl_dataset(path = None):\n",
    "    with open(path,'r') as f:\n",
    "        return list(map(lambda x : json.loads(x),f.readlines()))\n",
    "\n",
    "ds_odissey  = load_jsonl_dataset ('annotated/odyssey_annotaded.jsonl') \n",
    "ds_calibre = load_jsonl_dataset ('annotated/dataset_annotated-fixed-done.jsonl') \n",
    "ds_crimeandpun =  load_jsonl_dataset ('annotated/crimeandpun.jsonl') \n",
    "ds_republic =  load_jsonl_dataset ('annotated/therepublic.jsonl') \n",
    "ds_goodreads = load_jsonl_dataset ('annotated/smaller_dataset_goodreads(ANNOTATED).jsonl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_calibre = prepro_jsonl_dataset(ds_calibre,augument_chance=0.9,book_list_to_pick=books,remove_negatives=True)\n",
    "ds_odissey = prepro_jsonl_dataset(ds_odissey,augument_chance=.9,book_list_to_pick=books,remove_negatives=True)\n",
    "ds_crimeandpun = prepro_jsonl_dataset(ds_crimeandpun,augument_chance=.9,book_list_to_pick=books,remove_negatives=True)\n",
    "ds_republic = prepro_jsonl_dataset(ds_republic,augument_chance=.9,book_list_to_pick=books,remove_negatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodreads dataset needs preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in ds_goodreads:\n",
    "    book = d['meta']['book']\n",
    "    \n",
    "    temp = d['text'].replace('[[BOOK]]',book)\n",
    "    d['text'] = temp\n",
    "    b = temp.find(book)\n",
    "    e = b + len(book)\n",
    "\n",
    "    #dict(start=5,end=14,text=\"Tal Perry\",label=\"Person\")\n",
    "    entities = {\n",
    "        'start' : b,\n",
    "        'end' : e,\n",
    "        'text' : book,\n",
    "        'label' : \"OBRA\",\n",
    "        'tag' : \"OBRA\"\n",
    "    }\n",
    "    if(d['labels']==['negative']):\n",
    "        d['entities'] = []\n",
    "    else:\n",
    "        d['entities'] = [entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153\n"
     ]
    }
   ],
   "source": [
    "dsi = []\n",
    "list_ds = [ds_calibre,ds_odissey,ds_crimeandpun,ds_republic]\n",
    "list_ds = [ds_calibre]\n",
    "for d in list_ds:\n",
    "\n",
    "    dsi.extend(d)\n",
    "print(len(dsi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(dsi)\n",
    "\n",
    "dataset_train = dsi[:-50]\n",
    "dataset_test = dsi[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('ner_datasets/dataset_annotated_ner_calibre.jsonl','w') as f:\n",
    "#    for js in ds: \n",
    "#        f.write(json.dumps(js) + '\\n')\n",
    "#    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert ENTITIES to Hugginface Format (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast, RobertaModel\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List,Any\n",
    "IntList = List[int] # A list of token_ids\n",
    "IntListList = List[IntList] # A List of List of token_ids, e.g. a Batch\n",
    "\n",
    "def align_tokens_and_annotations_bilou(tokenized, annotations):\n",
    "    tokens = tokenized.tokens\n",
    "    aligned_labels = [\"O\"] * len(\n",
    "        tokens\n",
    "    )  # Make a list to store our labels the same length as our tokens\n",
    "    for anno in annotations:\n",
    "        annotation_token_ix_set = (\n",
    "            set()\n",
    "        )  # A set that stores the token indices of the annotation\n",
    "        for char_ix in range(anno[\"start\"], anno[\"end\"]):\n",
    "\n",
    "            token_ix = tokenized.char_to_token(char_ix)\n",
    "            if token_ix is not None:\n",
    "                annotation_token_ix_set.add(token_ix)\n",
    "        if len(annotation_token_ix_set) == 1:\n",
    "            # If there is only one token\n",
    "            token_ix = annotation_token_ix_set.pop()\n",
    "            prefix = (\n",
    "                \"U\"  # This annotation spans one token so is prefixed with U for unique\n",
    "            )\n",
    "            aligned_labels[token_ix] = f\"{prefix}-{anno['label']}\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            last_token_in_anno_ix = len(annotation_token_ix_set) - 1\n",
    "            for num, token_ix in enumerate(sorted(annotation_token_ix_set)):\n",
    "                if num == 0:\n",
    "                    prefix = \"B\"\n",
    "                elif num == last_token_in_anno_ix:\n",
    "                    prefix = \"L\"  # Its the last token\n",
    "                else:\n",
    "                    prefix = \"I\"  # We're inside of a multi token annotation\n",
    "                aligned_labels[token_ix] = f\"{prefix}-{anno['label']}\"\n",
    "    return aligned_labels\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "class LabelSet:\n",
    "    def __init__(self, labels: List[str]):\n",
    "        self.labels_to_id = {}\n",
    "        self.ids_to_label = {}\n",
    "        self.labels_to_id[\"O\"] = 0\n",
    "        self.ids_to_label[0] = \"O\"\n",
    "        num = 0  # in case there are no labels\n",
    "        # Writing BILU will give us incremntal ids for the labels\n",
    "        for _num, (label, s) in enumerate(itertools.product(labels, \"BILU\")):\n",
    "            num = _num + 1  # skip 0\n",
    "            l = f\"{s}-{label}\"\n",
    "            self.labels_to_id[l] = num\n",
    "            self.ids_to_label[num] = l\n",
    "        # Add the OUTSIDE label - no label for the token\n",
    "\n",
    "    def get_aligned_label_ids_from_annotations(self, tokenized_text, annotations):\n",
    "        raw_labels = align_tokens_and_annotations_bilou(tokenized_text, annotations)    \n",
    "        return list(map(self.labels_to_id.get, raw_labels))\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "@dataclass\n",
    "class TrainingExample:\n",
    "    input_ids: IntList\n",
    "    attention_masks: IntList\n",
    "    labels: IntList\n",
    "\n",
    "\n",
    "class TraingDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Any,\n",
    "        label_set: LabelSet,\n",
    "        tokenizer: PreTrainedTokenizerFast,\n",
    "        tokens_per_batch=32,\n",
    "        window_stride=None,\n",
    "    ):\n",
    "        self.label_set = label_set\n",
    "        if window_stride is None:\n",
    "            self.window_stride = tokens_per_batch\n",
    "        self.tokenizer = tokenizer\n",
    "        for example in data:\n",
    "            # changes tag key to label\n",
    "            for a in example[\"entities\"]:\n",
    "                a[\"label\"] = a[\"tag\"]\n",
    "                pass\n",
    "        self.texts = []\n",
    "        self.annotations = []\n",
    "\n",
    "        for example in data:\n",
    "            self.texts.append(example[\"text\"])\n",
    "            self.annotations.append(example[\"entities\"])\n",
    "        ###TOKENIZE All THE DATA\n",
    "        tokenized_batch = self.tokenizer(self.texts, add_special_tokens=False)\n",
    "        ###ALIGN LABELS ONE EXAMPLE AT A TIME\n",
    "        aligned_labels = []\n",
    "        for ix in range(len(tokenized_batch.encodings)):\n",
    "            encoding = tokenized_batch.encodings[ix]\n",
    "            raw_annotations = self.annotations[ix]            \n",
    "            aligned = label_set.get_aligned_label_ids_from_annotations(\n",
    "                encoding, raw_annotations\n",
    "            )\n",
    "            aligned_labels.append(aligned)\n",
    "        ###END OF LABEL ALIGNMENT\n",
    "\n",
    "        ###MAKE A LIST OF TRAINING EXAMPLES. (This is where we add padding)\n",
    "        self.training_examples: List[TrainingExample] = []\n",
    "        empty_label_id = \"O\"\n",
    "        for encoding, label in zip(tokenized_batch.encodings, aligned_labels):\n",
    "            length = len(label)  # How long is this sequence\n",
    "            for start in range(0, length, self.window_stride):\n",
    "\n",
    "                end = min(start + tokens_per_batch, length)\n",
    "\n",
    "                # How much padding do we need ?\n",
    "                padding_to_add = max(0, tokens_per_batch - end + start)\n",
    "                self.training_examples.append(\n",
    "                    TrainingExample(\n",
    "                        # Record the tokens\n",
    "                        input_ids=encoding.ids[start:end]  # The ids of the tokens\n",
    "                        + [self.tokenizer.pad_token_id]\n",
    "                        * padding_to_add,  # padding if needed\n",
    "                        labels=(\n",
    "                            label[start:end]\n",
    "                            + [-100] * padding_to_add  # padding if needed\n",
    "                        ),  # -100 is a special token for padding of labels,\n",
    "                        attention_masks=(\n",
    "                            encoding.attention_mask[start:end]\n",
    "                            + [0]\n",
    "                            * padding_to_add  # 0'd attenetion masks where we added padding\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.training_examples)\n",
    "\n",
    "    def __getitem__(self, idx) -> TrainingExample:\n",
    "\n",
    "        return self.training_examples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraingingBatch:\n",
    "    def __getitem__(self, item):\n",
    "        return getattr(self, item)\n",
    "\n",
    "    def __init__(self, examples: List[TrainingExample]):\n",
    "        self.input_ids: torch.Tensor\n",
    "        self.attention_masks: torch.Tensor\n",
    "        self.labels: torch.Tensor\n",
    "        input_ids: IntListList = []\n",
    "        masks: IntListList = []\n",
    "        labels: IntListList = []\n",
    "        for ex in examples:\n",
    "            input_ids.append(ex.input_ids)\n",
    "            masks.append(ex.attention_masks)\n",
    "            labels.append(ex.labels)\n",
    "        self.input_ids = torch.LongTensor(input_ids)\n",
    "        self.attention_masks = torch.LongTensor(masks)\n",
    "        self.labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "label_set = LabelSet(labels=[\"OBRA\"])\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "ds = TraingDataset(\n",
    "    data=dataset_train, tokenizer=tokenizer, label_set=label_set, tokens_per_batch=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers import RobertaForTokenClassification\n",
    "\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=len(ds.label_set.ids_to_label.values())\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "nb_grad_acc_steps = 2\n",
    "warmup_steps = 1\n",
    "num_epochs = 5\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ds,\n",
    "    collate_fn=TraingingBatch,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "nb_training_steps = len(dataloader)//nb_grad_acc_steps\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,num_training_steps=nb_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def check_accuracy_model(model,dataset_raw):\n",
    "\n",
    "    outs = []\n",
    "    for d in dataset_raw:\n",
    "\n",
    "            y_pred = ''\n",
    "            if len(d['entities'])>0:\n",
    "            \n",
    "                y_true = d['entities'][0]['text']\n",
    "            else:\n",
    "                y_true = ''\n",
    "                \n",
    "            inputs = tokenizer(d['text'], return_tensors=\"pt\",truncation=True,padding=True).to(device)\n",
    "\n",
    "            logits = model(**inputs)\n",
    "\n",
    "            idx = torch.nonzero(torch.argmax(logits[0][0],axis=1))\n",
    "\n",
    "            if (len(idx)):\n",
    "                ids_labeled = inputs.input_ids[0][idx]\n",
    "                tokens = tokenizer.convert_ids_to_tokens(ids_labeled)\n",
    "                y_pred = tokenizer.convert_tokens_to_string(tokens).strip()\n",
    "\n",
    "                success = y_pred.find(y_true)!=-1\n",
    "                outs.append(success)\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "            outs.append(y_pred==y_true)\n",
    "\n",
    "                \n",
    "\n",
    "    return np.mean(outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=0/5: 100%|██████████| 395/395 [00:23<00:00, 16.91it/s, loss=0.054]   \n",
      "Epoch=1/5:   1%|          | 2/395 [00:00<00:23, 16.65it/s, loss=0.0154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch val loss Goodreads:0.5887096774193549 Val Set:0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=1/5: 100%|██████████| 395/395 [00:23<00:00, 16.87it/s, loss=0.0513]  \n",
      "Epoch=2/5:   1%|          | 2/395 [00:00<00:24, 15.87it/s, loss=0.0198] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch val loss Goodreads:0.5887096774193549 Val Set:0.7551020408163265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=2/5: 100%|██████████| 395/395 [00:23<00:00, 16.47it/s, loss=0.00391] \n",
      "Epoch=3/5:   1%|          | 2/395 [00:00<00:24, 16.07it/s, loss=0.00465]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch val loss Goodreads:0.5887096774193549 Val Set:0.7551020408163265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=3/5: 100%|██████████| 395/395 [00:23<00:00, 16.48it/s, loss=0.138]   \n",
      "Epoch=4/5:   1%|          | 2/395 [00:00<00:23, 16.74it/s, loss=0.0149]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch val loss Goodreads:0.5887096774193549 Val Set:0.7551020408163265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch=4/5: 100%|██████████| 395/395 [00:23<00:00, 16.77it/s, loss=0.0129]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch val loss Goodreads:0.5887096774193549 Val Set:0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    iterator = dataloader.__iter__()\n",
    "\n",
    "    loop = tqdm(range(int(nb_training_steps)))\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i_train in loop:\n",
    "        \n",
    "        batch = next(iterator)\n",
    "            \n",
    "        device = 'cuda'\n",
    "        input_ids = batch.input_ids.to(device)\n",
    "        attention_masks = batch.attention_masks.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "\n",
    "        loss, logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_masks,\n",
    "            labels=labels,\n",
    "            return_dict=False\n",
    "        )\n",
    "        \n",
    "        loss = loss/nb_grad_acc_steps\n",
    "        loss.backward()  \n",
    "        if (i_train+1) % nb_grad_acc_steps == 0:      \n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()   \n",
    "            \n",
    "        loop.set_description(f'Epoch={epoch}/{num_epochs}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    #gd_val = check_accuracy_model(model,ds_goodreads)\n",
    "    val_val = check_accuracy_model(model,dataset_test)\n",
    "\n",
    "    print(f'Epoch val loss Goodreads:{gd_val} Val Set:{val_val}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.device"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model.save_pretrained(f\"fine-tuned-model-ner-better-data-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['O', 'B-OBRA', 'I-OBRA', 'L-OBRA', 'U-OBRA'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.label_set.ids_to_label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lira/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "model = RobertaForTokenClassification.from_pretrained(\"fine-tuned-model-ner-better-data-3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_if_citation_ner\n",
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Prince The Republic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,'Reading The Prince and The Republic has changed my life')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meditations'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,'The prince reads Marcus Aurelius Meditations to relax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Odyssey'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,\"When Odysseus returns to Ithaca in Book 13 of The Odyssey, Athena disguises him as an old beggar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Infinite Jest'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,\"But these more outré materials combine to form what is finally a thematic second tier. The foreground of Infinite Jest features three basic plot systems. At the center of one is Hal Incandenza, an adolescent tennis star attending Enfield Tennis Academy (ETA), which his family founded,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Henry IV'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,\"the commencement of war a herald might be called upon to recite the causes of the conflict; in effect, to provide the motivation. In Shakespeare's Henry IV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meditations'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,\"is impersonal in the Meditations agrees closely with Epictetus. Marcus Aurelius is doubtful about immortality, but says, as a Christian might: 'Since it is possible th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moby-Dick'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,\"8 Melville’s Moby-Dick, for instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([24], dtype='int64', name='id')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "metadata_calibre = pickle.load(open( \"pickled_metadata/calibre_metadata.p\", \"rb\" ))\n",
    "metadata_calibre.query('clean_title==\"Story of Philosophy\"').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nietz = []\n",
    "with open(f'books_raw/{186}.txt', 'r') as book_text:\n",
    "    nietz.append(book_text.readlines())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in nietz[0]:\n",
    "    if line.find('The New Republic')!=-1:\n",
    "        sentence = line\n",
    "        #print(check_if_citation_ner(model,tokenizer,line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sentence+sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sentence, return_tensors=\"pt\",truncation=True,padding=True)\n",
    "inputs.input_ids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on a Batch directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_citation_ner_multiline(model,tokenizer,sentences):\n",
    "\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\",truncation=True,padding=True)\n",
    "\n",
    "    logits = model(**inputs)\n",
    "    idx = torch.nonzero(torch.argmax(logits[0][0],axis=1))\n",
    "\n",
    "\n",
    "\n",
    "    num_sents = logits[0].shape[0]\n",
    "    idx_sentence = torch.nonzero(torch.argmax(logits[0],axis=2)).numpy()\n",
    "\n",
    "    dict_tokens_idx = {num:[] for num in range(num_sents)}\n",
    "\n",
    "    for row,idx in idx_sentence:\n",
    "        dict_tokens_idx[row].append(idx)\n",
    "    books_found = []\n",
    "    for row,ids in dict_tokens_idx.items():\n",
    "        ids_labeled = inputs.input_ids[row][ids]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(ids_labeled)\n",
    "        books_found.append(tokenizer.convert_tokens_to_string(tokens).strip())\n",
    "    \n",
    "    return books_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('to_annotate/output_ner_multi.jsonl','r') as f:\n",
    "    \n",
    "    ds_goodreads = list(map(lambda x : json.loads(x),f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Art thou there, truepenny? -- Interesting only to the parish clerk. I mean, we have the plays. I mean when we read the poetry of King Lear what is it to us how the poet lived? As for living, our servants can do that for us, Villiers de l'Isle has said.\",\n",
       " 'labels': ['positive'],\n",
       " 'detected_ner': '-1',\n",
       " 'meta': {'book': 'King Lear'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_goodreads[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The manuscript of the first edition of Moby Dick was submitted in December 2009 and finalized in January 2010, after a version of the financial reform bill passed The Republic but before formal debate began in The Republic.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 796 ms, sys: 2.65 ms, total: 799 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(4):\n",
    "    check_if_citation_ner(model,tokenizer,sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 ms, sys: 28 ms, total: 571 ms\n",
      "Wall time: 100 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Moby Dick The The',\n",
       " 'Moby Dick The The',\n",
       " 'Moby Dick The The',\n",
       " 'Moby Dick The The']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "check_if_citation_ner_multiline(model,tokenizer,[sentence]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'King Lear'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_citation_ner(model,tokenizer,ds_goodreads[70]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_citation_model = True\n",
    "create_dataset = False\n",
    "\n",
    "from utils import find_any_book_calibre,search_book_pubdate_by_alias\n",
    "\n",
    "lookup_func = find_any_book_calibre\n",
    "\n",
    "using_goodreads=False\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def process_book(tup,model,tokenizer):\n",
    "             \n",
    "                        return (current_book_name,edges_to_add,pieces_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_book = 24\n",
    "\n",
    "books_memory = []\n",
    "with open(f'books_raw/{idx_book}.txt', 'r') as book_text:\n",
    "    books_memory.append(book_text.readlines())\n",
    "    \n",
    "tup = metadata_calibre.index[idx_book],metadata_calibre['aliases'][idx_book],metadata_calibre['clean_title'][idx_book],books_memory[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_book' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_book' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_book(tup,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BookProcesserFactory\n",
    "\n",
    "bkp = BookProcesserFactory(create_dataset = False,\n",
    "                    verbose = False,\n",
    "                    use_citation_model =True,\n",
    "                    metadata_to_use = 'calibre'       \n",
    "                )\n",
    "\n",
    "book_processer = bkp.GetProcessFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "CPU times: user 13.8 s, sys: 0 ns, total: 13.8 s\n",
      "Wall time: 2.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Story of Philosophy',\n",
       " [('Story of Philosophy', 'The Republic'),\n",
       "  ('Story of Philosophy', 'The Republic'),\n",
       "  ('Story of Philosophy', 'The Republic'),\n",
       "  ('Story of Philosophy', 'Crito')],\n",
       " [])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "book_processer(tup,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-81ed170791b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooks_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "books_memory[0][i:i+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'The Birth of Traged Untimely Meditations All Too Human Assorted Opin The Wand The Dawn The Gay Science Ecce Homo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = ['The Birth of Tragedy', 'Thus Spoke Zarathustra', 'Ecce Homo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in found:\n",
    "    filtered_regex = [word for word in w.split() if not word.lower() in stopwords.words()]\n",
    "    for w2 in filtered_regex:\n",
    "        if words.find(w2)!=-1:\n",
    "            print(w2)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
