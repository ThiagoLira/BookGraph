{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import re \n",
    "import platform\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_title(input_name):\n",
    "    # first do generic cleaning\n",
    "    input_name = input_name.split('_')[0]\n",
    "    input_name = input_name.split('(')[0]\n",
    "    input_name = input_name.split('[')[0]\n",
    "    \n",
    "    # if name is too short after split, don't do this\n",
    "    if (not len(input_name.split(':')[0].split())==1):\n",
    "        input_name = input_name.split(':')[0]\n",
    "    \n",
    "    input_name = input_name.strip()\n",
    "    # THEN apply hard coded rule\n",
    "    if input_name in dict_subs:\n",
    "        input_name = dict_subs[input_name]\n",
    "    return input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lib = True\n",
    "calibre_library_path = '/mnt/c/Users/Thiago/Calibre - Open Culture/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_books = Path(Path.cwd(),'books_raw')\n",
    "if not os.path.exists(dir_books):\n",
    "    os.makedirs(dir_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if copy_lib:\n",
    "\n",
    "    root = calibre_library_path\n",
    "\n",
    "    pattern = re.compile('^.*\\((.*)\\)$')\n",
    "\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            if(Path(name).suffix=='.txt'):\n",
    "                path_origin = os.path.join(path, name)\n",
    "\n",
    "                p = Path(path_origin).parts[-2]\n",
    "                id_book = re.match(pattern,p)[1]            \n",
    "                # lets work with raw file names, clean name on metadata!\n",
    "                # clean_name = clean_title(clean_name)\n",
    "\n",
    "\n",
    "                path_dest = os.path.join(dir_books,id_book + '.txt')\n",
    "                \n",
    "                if not(os.path.isfile(f'{dir_books}/{id_book}.txt')):\n",
    "                    copyfile(path_origin, path_dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_path = str(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Metadata from my books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_calibre = pd.read_csv('My books.csv')\n",
    "metadata_calibre = metadata_calibre.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete books not found from metadata for the rest of the analysis\n",
    "for id_book in metadata_calibre.index:\n",
    "    \n",
    "    if not os.path.isfile(f'{loc_path}/books_raw/{id_book}.txt'):\n",
    "        print(f'{loc_path}/books_raw/{id_book}.txt')\n",
    "        metadata_calibre = metadata_calibre.drop(metadata_calibre.query(f\"id=={id_book}\").index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HARD CODE CORRECTIONS TO TITLE -> CREATE CLEAN_TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_subs = {\n",
    "    'ULYSSES ' : \"Ulysses\",\n",
    "    'The Poetics. Translated From Greek Into English and From Arabic Into Latin' : \"Aristotle's Poetics\",\n",
    "    'War and Peace by Leo Tolstoy' : 'War and Peace',\n",
    "    'Douglas Adams, The Restaurant at the End of the Universe #2 ' : \"The Restaurant at the End of the Universe\",\n",
    "    'CliffsComplete King Lear' : \"King Lear\",\n",
    "    'Kant': \"Kant Complete Works\",\n",
    "    'Bach' : \"Music in the Castle of Heaven\",\n",
    "    'Oscar Wilde' : \"Oscars Wilde Complete Works\",\n",
    "    'Plato' : 'Plato Five Dialogues',\n",
    "    'tmp4C9D' : \"The Writer's Journey\",\n",
    "    'Islam' : \"Islam: A Short Story\",\n",
    "    'Story' : 'Story: Style, Structure, Substance',\n",
    "    'Delphi Collected Works of Arthur Schopenhauer' : \"The Collected Works of Arthur Schopenhauer\",\n",
    "    'Justice' : \"Justice: What's the Right Thing to do?\",\n",
    "    'Hamlet, Prince of Denmark' : \"Hamlet\",\n",
    "    'The Dream of a Ridiculous Man Annotated and Illustrated Book' : 'The Dream of a Ridiculous Man',\n",
    "    'Collected Fictions' : \"Borges Fictions\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create clean title column!!!\n",
    "metadata_calibre['clean_title'] = metadata_calibre['title'].apply(clean_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD ALIASES\n",
    "### DONT CORRECT TYPOS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fantasy = False\n",
    "\n",
    "names = []\n",
    "metadata_aliases = {}\n",
    "\n",
    "for id_,stem in zip(metadata_calibre.index,metadata_calibre['clean_title']):\n",
    "                if(stem=='Keats Complete Works'):\n",
    "                    metadata_aliases.update({id_:[\"Keat's Hyperion\"]})\n",
    "                elif(stem=='Kant Complete Works'):\n",
    "                     metadata_aliases.update({id_: ['Critique of Pure Reason']})\n",
    "                elif(stem=='Oscar Wilde Complete Works'):\n",
    "                     metadata_aliases.update({id_: ['The Importance of Being Earnest','Salomé']})\n",
    "                elif(stem=='The Collected Works of Arthur Schopenhauer'):\n",
    "                     metadata_aliases.update({id_: ['The World As Will And Idea']})\n",
    "                elif(stem=='Plato Five Dialogues'):\n",
    "                    metadata_aliases.update({id_: \n",
    "                                  [\n",
    "                                        'Euthyphro',\n",
    "                                        \"Socrate's Apology\",\n",
    "                                        'Crito',\n",
    "                                        'Meno',\n",
    "                                        'Phaedo'\n",
    "                                  ]})\n",
    "                elif(stem=='Ulysses'):\n",
    "                    metadata_aliases.update({id_: [\"Joyce's Ulysses\"]})\n",
    "                elif(stem=='Borges Fictions'):\n",
    "                     metadata_aliases.update({id_:\n",
    "                                 \n",
    "                                 [\n",
    "                                        'Tlön, Uqbar, Orbis Tertius',\n",
    "                                        'Pierre Menard, Author of the Quixote',\n",
    "                                        'The Circular Ruins',\n",
    "                                        'The Lottery in Babylon',\n",
    "                                        'A Survey of the Works of Herbert Quain',\n",
    "                                        'The Library of Babel',\n",
    "                                        'The Garden of Forking Paths',\n",
    "                                        'The Aleph',\n",
    "                                 ]})\n",
    "                elif(stem=='Dune'):\n",
    "                     metadata_aliases.update({id_: [\"Dune\"]})\n",
    "                elif(stem=='The Republic of Plato'):\n",
    "                     metadata_aliases.update({id_: [\"Plato's Republic\",\"The Republic\"]})\n",
    "                elif(stem=='Meditations'):\n",
    "                     metadata_aliases.update({id_: [\"Marcus Aurelius's Meditations\"]})\n",
    "                elif(stem=='The Complete Essays'):\n",
    "                     metadata_aliases.update({id_: [\"Montaigne's Essays\"]})\n",
    "                elif(stem=='Ethics'):\n",
    "                     metadata_aliases.update({id_: [\"Spinoza's Ethics\"]})\n",
    "                else:\n",
    "                     if (len(stem.split())!=1):   \n",
    "                        metadata_aliases.update({id_:[stem]})\n",
    "                     else:\n",
    "                        metadata_aliases.update({id_:[f'{stem}']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove goddamn The Dispossed\n",
    "try:\n",
    "    metadata_calibre = metadata_calibre.drop(index=20)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add aliases to metadata\n",
    "metadata_calibre['aliases'] = pd.Series(metadata_aliases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclude books from analysis by name!\n",
    "## MY books\n",
    "#### e.g. dictionaries, fantasy books etc, books not in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# languages\n",
    "metadata_calibre = metadata_calibre.query('languages==\"eng\"')\n",
    "\n",
    "# no dictionaries\n",
    "metadata_calibre = metadata_calibre[~metadata_calibre[\"title\"].str.contains('ictionary', na=False)]\n",
    "\n",
    "# no poetry\n",
    "metadata_calibre = metadata_calibre[~metadata_calibre[\"title\"].str.contains('Poems', na=False)]\n",
    "\n",
    "\n",
    "# take modern fantasy out \n",
    "list_fantasy_writers = [\n",
    "                        'Brandon Sanderson',\n",
    "                        'Patrick Rothfuss',\n",
    "                        'Jim Butcher',\n",
    "                        'Brent Weeks',\n",
    "                        'Robin Hobb',\n",
    "                        'Joe Abercrombie',\n",
    "                        'Robert Jordan',\n",
    "                        'Jim Butcher & Mark Powers',\n",
    "                        'Stephen King',\n",
    "                        'Terry Pratchett',\n",
    "                        'Neil Gaiman & Terry Pratchett',\n",
    "                        'Jo Nesbø',\n",
    "                       ]\n",
    "\n",
    "metadata_calibre = metadata_calibre[~metadata_calibre[\"authors\"].isin(list_fantasy_writers)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export some metadata to make a table on webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_export = ['clean_title','authors','pubdate']\n",
    "metadata_calibre[to_export].to_csv('web/book_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcode some books to not look for citations inside then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these don't cite other books\n",
    "# so we just use them to point other citations\n",
    "excluded_books = ['King Lear','Hamlet','The Tempest','Othello','The Odyssey','Ulysses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph of Citations between my books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_word(s,w):\n",
    "#    return re.search(r'(\\b|,){}(\\b|[?!.,])'.format(w), s)\n",
    "# in awk\n",
    "# awk '/(\\s|,)Nietzsche(\\s|[?!.,])/{print NR}' 135.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make big REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# humongous regex \n",
    "list_words = []\n",
    "for id_book,aliases_target_book in zip(metadata_calibre.index,metadata_calibre['aliases']):\n",
    "    for book in aliases_target_book:\n",
    "        list_words.append(book)\n",
    "        \n",
    "\n",
    "regex = '[, ]('\n",
    "for word in list_words:\n",
    "    word = re.escape(word)\n",
    "    regex+=f'{word}|'\n",
    "regex = regex[:-1]\n",
    "regex+=')[?!., ]'\n",
    "\n",
    "humongous_regex = re.compile(regex)\n",
    "\n",
    "def find_any_book(s):\n",
    "    return re.findall(humongous_regex, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_any_book('Eu gosto de , Hamlet, ??')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "os.makedirs(loc_path + '/pickled_metadata')\n",
    "\n",
    "pickle.dump( metadata_calibre, open( \"pickled_metadata/calibre_metadata.p\", \"wb\" ) )\n",
    "pickle.dump( humongous_regex, open( \"pickled_metadata/calibre_regex.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Goodreads data and Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_orig = pd.read_csv('goodreads_ds.csv',error_bad_lines=False)\n",
    "\n",
    "\n",
    "metadata_goodreads = df_orig[df_orig['language_code']=='eng']\n",
    "metadata_goodreads['clean_title'] = metadata_goodreads['title'].apply(clean_title)\n",
    "metadata_goodreads['num_words_title'] = metadata_goodreads['clean_title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# remove some random unknown books\n",
    "metadata_goodreads = metadata_goodreads[metadata_goodreads['ratings_count']>200]\n",
    "\n",
    "### just to make dataset\n",
    "#df = df[df['num_words_title']<=2]\n",
    "metadata_goodreads['len_clean_title'] = metadata_goodreads['clean_title'].apply(len)\n",
    "metadata_goodreads = metadata_goodreads[metadata_goodreads['len_clean_title']>5]\n",
    "\n",
    "metadata_goodreads = metadata_goodreads.drop_duplicates(subset=['clean_title'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use following unigram data to filter book titles that are too common words like \"Divine\" or \"Cathedral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load frequency dataset \n",
    "freq_ds = pd.read_csv('unigram_freq.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking(book):\n",
    "    try:\n",
    "        return int(freq_ds.query(f'word==\"{book.lower()}\"').index.values[0])\n",
    "    except: \n",
    "        return 100000000000\n",
    "\n",
    "\n",
    "metadata_goodreads['word_freq_on_english'] = metadata_goodreads['clean_title'].apply(get_ranking)\n",
    "metadata_calibre['word_freq_on_english'] = metadata_calibre['clean_title'].apply(get_ranking)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_common_word_titles = list(metadata_goodreads.sort_values(by='word_freq_on_english')['clean_title'].head(20).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in too_common_word_titles:\n",
    "    print(word,metadata_goodreads.query(f'clean_title==\"{word}\"')[['title','year_first_published','word_freq_on_english']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by books whose names are too common on the english language as words\n",
    "\n",
    "metadata_goodreads = metadata_goodreads[metadata_goodreads['word_freq_on_english']>3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_goodreads[['clean_title','title','word_freq_on_english']].to_csv('word_freq_goodreads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_calibre[['clean_title','title','word_freq_on_english']].to_csv('word_freq_calibre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_book_list = ['Divine','Caesar','Silence','Cathedral']\n",
    "bad_book_list.extend(too_common_word_titles)\n",
    "\n",
    "for bad_book in bad_book_list:\n",
    "    \n",
    "    metadata_goodreads= metadata_goodreads.drop(index=metadata_goodreads.query(f'clean_title==\"{bad_book}\"').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_aliases = {}\n",
    "\n",
    "for id_,stem in zip(metadata_goodreads.index,metadata_goodreads['clean_title']):\n",
    "                     if (len(stem.split())!=1):   \n",
    "                        metadata_aliases.update({id_:[stem]})\n",
    "                     else:\n",
    "                        metadata_aliases.update({id_:[f'{stem}']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_goodreads['aliases'] = pd.Series(metadata_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by descending number of words so books like Journey are not matched before Writer's Journey!\n",
    "metadata_goodreads = metadata_goodreads.sort_values(by='num_words_title', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove books from goodreads ds that are already on my list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_book,aliases_target_book in zip(metadata_calibre.index,metadata_calibre['aliases']):\n",
    "    for book in aliases_target_book:\n",
    "        if book in list(metadata_goodreads.clean_title):\n",
    "            metadata_goodreads = metadata_goodreads.drop(index=metadata_goodreads.query(f'clean_title==\"{book}\"').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add citations from my books to goodreads books to graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex for Goodreads books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# humongous regex for goodreads\n",
    "list_words_goodreads = []\n",
    "for id_book,aliases_target_book in zip(metadata_goodreads.bookID,metadata_goodreads['aliases']):\n",
    "    for book in aliases_target_book:\n",
    "        list_words_goodreads.append(book)\n",
    "        \n",
    "list_words_goodreads = list(set(list_words_goodreads))        \n",
    "\n",
    "regex = '[, ]('\n",
    "for word in list_words_goodreads:\n",
    "    word = re.escape(word)\n",
    "    regex+=f'{word}|'\n",
    "regex = regex[:-1]\n",
    "regex+=')[?!., ]'\n",
    "\n",
    "humongous_regex_goodreads = re.compile(regex)\n",
    "\n",
    "def find_any_book_goodreads(s):\n",
    "    return re.findall(humongous_regex_goodreads, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"The Story of Philosophy\" in list_words_goodreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( metadata_goodreads, open( \"pickled_metadata/metadata_goodreads.p\", \"wb\" ) )\n",
    "pickle.dump( humongous_regex_goodreads, open( \"pickled_metadata/goodreads_regex.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
